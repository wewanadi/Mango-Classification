{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5600, 300, 300, 3)\n",
      "(5600,)\n",
      "(800, 300, 300, 3)\n",
      "(800,)\n"
     ]
    }
   ],
   "source": [
    "# Import Data\n",
    "image_shape = 300\n",
    "\n",
    "import numpy as np\n",
    "X_train = np.load('./mango_train_data.npy',allow_pickle=True)\n",
    "X_test = np.load('./mango_dev_data.npy',allow_pickle=True)\n",
    "\n",
    "import cv2\n",
    "def resize_mango(mango_data, size):\n",
    "    res_mango = list()\n",
    "    for mango in mango_data:\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        large_size = max(int(np.shape(mango)[0]),int(np.shape(mango)[1]))\n",
    "        mango = cv2.copyMakeBorder(mango,int((large_size-np.shape(mango)[0])/2),int((large_size-np.shape(mango)[0])/2)\n",
    "                               ,int((large_size-np.shape(mango)[1])/2),int((large_size-np.shape(mango)[1])/2)\n",
    "                               ,cv2.BORDER_REPLICATE)\n",
    "        res_mango.append(cv2.resize(mango,(size,size),interpolation = cv2.INTER_CUBIC))    \n",
    "#     np.save('./res_{}_mango({}).npy'.format(name,size),res_mango)\n",
    "    return np.array(res_mango)\n",
    "\n",
    "X_train = resize_mango(X_train,image_shape)\n",
    "y_train = np.load('./mango_train_label.npy',allow_pickle=True)\n",
    "X_test = resize_mango(X_test,image_shape)\n",
    "y_test = np.load('./mango_dev_label.npy',allow_pickle=True)\n",
    "\n",
    "print (np.shape(X_train))\n",
    "print (np.shape(y_train))\n",
    "print (np.shape(X_test))\n",
    "print (np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Data Generator\n",
    "import Augmentor\n",
    "\n",
    "train = Augmentor.Pipeline()\n",
    "\n",
    "train.random_brightness(probability=0.6, min_factor=0.9, max_factor=1.2)\n",
    "train.random_color(probability=0.6, min_factor=0.9, max_factor=1.2)\n",
    "train.random_contrast(probability=0.6, min_factor=0.95, max_factor=1.1)\n",
    "train.random_distortion(probability=0.5, grid_width=4, grid_height=8, magnitude=6)\n",
    "train.skew(probability=0.8, magnitude=0.5)\n",
    "train.shear(probability=0.7, max_shear_left=20, max_shear_right=20)\n",
    "train.zoom(probability=0.5, min_factor=1.1, max_factor=1.3)\n",
    "train.rotate(probability=1, max_left_rotation=24, max_right_rotation=24)\n",
    "train.rotate_random_90(0.75)\n",
    "train.zoom(probability=0.2, min_factor=1.1, max_factor=1.3)\n",
    "train.flip_random(0.75)\n",
    "train.resize(probability=1, width=image_shape, height=image_shape, resample_filter=u'BICUBIC')\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "traingen = ImageDataGenerator(\n",
    "      preprocessing_function = train.keras_preprocess_func(),\n",
    ")\n",
    "\n",
    "test = Augmentor.Pipeline()\n",
    "test.zoom(probability=1, min_factor=1.1, max_factor=1.2)\n",
    "test.resize(1.0, image_shape, image_shape)\n",
    "\n",
    "testgen = ImageDataGenerator(\n",
    "      preprocessing_function = test.keras_preprocess_func(),  \n",
    ")\n",
    "\n",
    "# 從中間切固定大小\n",
    "# crop_by_size(probability, width, height, centre=True) \n",
    "# 從中間擷取隨機大小 percentage_area(隨機的大小)\n",
    "# crop_centre(probability, percentage_area, randomise_percentage_area=False)\n",
    "# 隨機擷取隨機大小 \n",
    "# crop_random(probability, percentage_area, randomise_percentage_area=False)\n",
    "# 翻轉\n",
    "# traingen.flip_random(0.75)\n",
    "# 圖內變形(小區域放大縮小扭曲)\n",
    "# traingen.gaussian_distortion(0.2, 2, 2, 1, \"bell\", \"in\")\n",
    "# 增加對比度\n",
    "# histogram_equalisation(probability=1.0)\n",
    "# 亮度 0黑 1原圖\n",
    "# random_brightness(probability, min_factor, max_factor)\n",
    "# 飽和度 1 原圖\n",
    "# random_color(probability, min_factor, max_factor)\n",
    "# 對比度 1 原圖\n",
    "# random_contrast(probability, min_factor, max_factor)\n",
    "# 圖內形變\n",
    "# random_distortion(probability=0.5, grid_width=4, grid_height=8, magnitude=5)\n",
    "# 轉成指定大小\n",
    "# resize(probability, width, height, resample_filter=u'BICUBIC')\n",
    "# 隨機旋轉(最多25)\n",
    "# rotate(probability=1, max_left_rotation=24, max_right_rotation=24)\n",
    "# 旋轉 90 的倍數\n",
    "# rotate_random_90(0.75)\n",
    "# 傾斜\n",
    "# skew(probability=0.5, magnitude=0.5)\n",
    "# 放大\n",
    "# zoom(probability=0.5, min_factor=1.1, max_factor=1.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"efficientnet-b3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 300, 300, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 150, 150, 40) 1080        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 150, 150, 40) 160         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 150, 150, 40) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 150, 150, 40) 360         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 150, 150, 40) 160         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 150, 150, 40) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 40)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 40)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 10)     410         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 40)     440         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 150, 150, 40) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 150, 150, 24) 960         block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 150, 150, 24) 96          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_dwconv (DepthwiseConv2D (None, 150, 150, 24) 216         block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_bn (BatchNormalization) (None, 150, 150, 24) 96          block1b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1b_activation (Activation) (None, 150, 150, 24) 0           block1b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_squeeze (GlobalAvera (None, 24)           0           block1b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reshape (Reshape)    (None, 1, 1, 24)     0           block1b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reduce (Conv2D)      (None, 1, 1, 6)      150         block1b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_expand (Conv2D)      (None, 1, 1, 24)     168         block1b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_excite (Multiply)    (None, 150, 150, 24) 0           block1b_activation[0][0]         \n",
      "                                                                 block1b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_conv (Conv2D)   (None, 150, 150, 24) 576         block1b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_bn (BatchNormal (None, 150, 150, 24) 96          block1b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_drop (FixedDropout)     (None, 150, 150, 24) 0           block1b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_add (Add)               (None, 150, 150, 24) 0           block1b_drop[0][0]               \n",
      "                                                                 block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 150, 150, 144 3456        block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 150, 150, 144 576         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 150, 150, 144 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 75, 75, 144)  1296        block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 75, 75, 144)  576         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 75, 75, 144)  0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 144)          0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 75, 75, 144)  0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 75, 75, 32)   4608        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 75, 75, 32)   128         block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 75, 75, 192)  6144        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 75, 75, 192)  768         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 75, 75, 192)  0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 75, 75, 192)  1728        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 75, 75, 192)  768         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 75, 75, 192)  0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 192)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 75, 75, 192)  0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 75, 75, 32)   6144        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 75, 75, 32)   128         block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (FixedDropout)     (None, 75, 75, 32)   0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 75, 75, 32)   0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_conv (Conv2D)    (None, 75, 75, 192)  6144        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_bn (BatchNormali (None, 75, 75, 192)  768         block2c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_activation (Acti (None, 75, 75, 192)  0           block2c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_dwconv (DepthwiseConv2D (None, 75, 75, 192)  1728        block2c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2c_bn (BatchNormalization) (None, 75, 75, 192)  768         block2c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2c_activation (Activation) (None, 75, 75, 192)  0           block2c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_squeeze (GlobalAvera (None, 192)          0           block2c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_excite (Multiply)    (None, 75, 75, 192)  0           block2c_activation[0][0]         \n",
      "                                                                 block2c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_conv (Conv2D)   (None, 75, 75, 32)   6144        block2c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_bn (BatchNormal (None, 75, 75, 32)   128         block2c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2c_drop (FixedDropout)     (None, 75, 75, 32)   0           block2c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_add (Add)               (None, 75, 75, 32)   0           block2c_drop[0][0]               \n",
      "                                                                 block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 75, 75, 192)  6144        block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 75, 75, 192)  768         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 75, 75, 192)  0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 38, 38, 192)  4800        block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 38, 38, 192)  768         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 38, 38, 192)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 192)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 192)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 38, 38, 192)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 38, 38, 48)   9216        block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 38, 38, 48)   192         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 38, 38, 288)  13824       block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 38, 38, 288)  1152        block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 38, 38, 288)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 38, 38, 288)  7200        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 38, 38, 288)  1152        block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 38, 38, 288)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 288)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 288)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 38, 38, 288)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 38, 38, 48)   13824       block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 38, 38, 48)   192         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (FixedDropout)     (None, 38, 38, 48)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 38, 38, 48)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_conv (Conv2D)    (None, 38, 38, 288)  13824       block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_bn (BatchNormali (None, 38, 38, 288)  1152        block3c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_activation (Acti (None, 38, 38, 288)  0           block3c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_dwconv (DepthwiseConv2D (None, 38, 38, 288)  7200        block3c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3c_bn (BatchNormalization) (None, 38, 38, 288)  1152        block3c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3c_activation (Activation) (None, 38, 38, 288)  0           block3c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_squeeze (GlobalAvera (None, 288)          0           block3c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reshape (Reshape)    (None, 1, 1, 288)    0           block3c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block3c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block3c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_excite (Multiply)    (None, 38, 38, 288)  0           block3c_activation[0][0]         \n",
      "                                                                 block3c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_conv (Conv2D)   (None, 38, 38, 48)   13824       block3c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_bn (BatchNormal (None, 38, 38, 48)   192         block3c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3c_drop (FixedDropout)     (None, 38, 38, 48)   0           block3c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_add (Add)               (None, 38, 38, 48)   0           block3c_drop[0][0]               \n",
      "                                                                 block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 38, 38, 288)  13824       block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 38, 38, 288)  1152        block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 38, 38, 288)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 19, 19, 288)  2592        block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 19, 19, 288)  1152        block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 19, 19, 288)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 288)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 288)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 19, 19, 288)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 19, 19, 96)   27648       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 19, 19, 96)   384         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 19, 19, 576)  55296       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 19, 19, 576)  2304        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 19, 19, 576)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 19, 19, 576)  5184        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 19, 19, 576)  2304        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 19, 19, 576)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 576)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 19, 19, 576)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 19, 19, 96)   55296       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 19, 19, 96)   384         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (FixedDropout)     (None, 19, 19, 96)   0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 19, 19, 96)   0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 19, 19, 576)  55296       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 19, 19, 576)  2304        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 19, 19, 576)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 19, 19, 576)  5184        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 19, 19, 576)  2304        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 19, 19, 576)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 576)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 19, 19, 576)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 19, 19, 96)   55296       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 19, 19, 96)   384         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (FixedDropout)     (None, 19, 19, 96)   0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 19, 19, 96)   0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_conv (Conv2D)    (None, 19, 19, 576)  55296       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_bn (BatchNormali (None, 19, 19, 576)  2304        block4d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_activation (Acti (None, 19, 19, 576)  0           block4d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_dwconv (DepthwiseConv2D (None, 19, 19, 576)  5184        block4d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4d_bn (BatchNormalization) (None, 19, 19, 576)  2304        block4d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4d_activation (Activation) (None, 19, 19, 576)  0           block4d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_squeeze (GlobalAvera (None, 576)          0           block4d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_excite (Multiply)    (None, 19, 19, 576)  0           block4d_activation[0][0]         \n",
      "                                                                 block4d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_conv (Conv2D)   (None, 19, 19, 96)   55296       block4d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_bn (BatchNormal (None, 19, 19, 96)   384         block4d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4d_drop (FixedDropout)     (None, 19, 19, 96)   0           block4d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_add (Add)               (None, 19, 19, 96)   0           block4d_drop[0][0]               \n",
      "                                                                 block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_conv (Conv2D)    (None, 19, 19, 576)  55296       block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_bn (BatchNormali (None, 19, 19, 576)  2304        block4e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_activation (Acti (None, 19, 19, 576)  0           block4e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_dwconv (DepthwiseConv2D (None, 19, 19, 576)  5184        block4e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4e_bn (BatchNormalization) (None, 19, 19, 576)  2304        block4e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4e_activation (Activation) (None, 19, 19, 576)  0           block4e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_squeeze (GlobalAvera (None, 576)          0           block4e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_excite (Multiply)    (None, 19, 19, 576)  0           block4e_activation[0][0]         \n",
      "                                                                 block4e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_conv (Conv2D)   (None, 19, 19, 96)   55296       block4e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_bn (BatchNormal (None, 19, 19, 96)   384         block4e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4e_drop (FixedDropout)     (None, 19, 19, 96)   0           block4e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_add (Add)               (None, 19, 19, 96)   0           block4e_drop[0][0]               \n",
      "                                                                 block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 19, 19, 576)  55296       block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 19, 19, 576)  2304        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 19, 19, 576)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 19, 19, 576)  14400       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 19, 19, 576)  2304        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 19, 19, 576)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 576)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 576)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 19, 19, 576)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 19, 19, 136)  78336       block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 19, 19, 136)  544         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 19, 19, 816)  110976      block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 19, 19, 816)  3264        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 19, 19, 816)  0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 19, 19, 816)  20400       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 19, 19, 816)  3264        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 19, 19, 816)  0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 816)          0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 19, 19, 816)  0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 19, 19, 136)  110976      block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 19, 19, 136)  544         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (FixedDropout)     (None, 19, 19, 136)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 19, 19, 136)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 19, 19, 816)  110976      block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 19, 19, 816)  3264        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 19, 19, 816)  0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 19, 19, 816)  20400       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 19, 19, 816)  3264        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 19, 19, 816)  0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 816)          0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 19, 19, 816)  0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 19, 19, 136)  110976      block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 19, 19, 136)  544         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (FixedDropout)     (None, 19, 19, 136)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 19, 19, 136)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_conv (Conv2D)    (None, 19, 19, 816)  110976      block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_bn (BatchNormali (None, 19, 19, 816)  3264        block5d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_activation (Acti (None, 19, 19, 816)  0           block5d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_dwconv (DepthwiseConv2D (None, 19, 19, 816)  20400       block5d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5d_bn (BatchNormalization) (None, 19, 19, 816)  3264        block5d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5d_activation (Activation) (None, 19, 19, 816)  0           block5d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_squeeze (GlobalAvera (None, 816)          0           block5d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_excite (Multiply)    (None, 19, 19, 816)  0           block5d_activation[0][0]         \n",
      "                                                                 block5d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_conv (Conv2D)   (None, 19, 19, 136)  110976      block5d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_bn (BatchNormal (None, 19, 19, 136)  544         block5d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5d_drop (FixedDropout)     (None, 19, 19, 136)  0           block5d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_add (Add)               (None, 19, 19, 136)  0           block5d_drop[0][0]               \n",
      "                                                                 block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_conv (Conv2D)    (None, 19, 19, 816)  110976      block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_bn (BatchNormali (None, 19, 19, 816)  3264        block5e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_activation (Acti (None, 19, 19, 816)  0           block5e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_dwconv (DepthwiseConv2D (None, 19, 19, 816)  20400       block5e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5e_bn (BatchNormalization) (None, 19, 19, 816)  3264        block5e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5e_activation (Activation) (None, 19, 19, 816)  0           block5e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_squeeze (GlobalAvera (None, 816)          0           block5e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_excite (Multiply)    (None, 19, 19, 816)  0           block5e_activation[0][0]         \n",
      "                                                                 block5e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_conv (Conv2D)   (None, 19, 19, 136)  110976      block5e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_bn (BatchNormal (None, 19, 19, 136)  544         block5e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5e_drop (FixedDropout)     (None, 19, 19, 136)  0           block5e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_add (Add)               (None, 19, 19, 136)  0           block5e_drop[0][0]               \n",
      "                                                                 block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 19, 19, 816)  110976      block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 19, 19, 816)  3264        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 19, 19, 816)  0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 10, 10, 816)  20400       block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 10, 10, 816)  3264        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 10, 10, 816)  0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 816)          0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 816)    0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 10, 10, 816)  0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 10, 10, 232)  189312      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 10, 10, 232)  928         block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 10, 10, 1392) 322944      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 10, 10, 1392) 5568        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 10, 10, 1392) 0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 10, 10, 1392) 34800       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 10, 10, 1392) 5568        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 10, 10, 1392) 0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1392)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 10, 10, 1392) 0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 10, 10, 232)  322944      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 10, 10, 232)  928         block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (FixedDropout)     (None, 10, 10, 232)  0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 10, 10, 232)  0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 10, 10, 1392) 322944      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 10, 10, 1392) 5568        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 10, 10, 1392) 0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 10, 10, 1392) 34800       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 10, 10, 1392) 5568        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 10, 10, 1392) 0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1392)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 10, 10, 1392) 0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 10, 10, 232)  322944      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 10, 10, 232)  928         block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (FixedDropout)     (None, 10, 10, 232)  0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 10, 10, 232)  0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 10, 10, 1392) 322944      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 10, 10, 1392) 5568        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 10, 10, 1392) 0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 10, 10, 1392) 34800       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 10, 10, 1392) 5568        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 10, 10, 1392) 0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1392)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 10, 10, 1392) 0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 10, 10, 232)  322944      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 10, 10, 232)  928         block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (FixedDropout)     (None, 10, 10, 232)  0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 10, 10, 232)  0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_conv (Conv2D)    (None, 10, 10, 1392) 322944      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_bn (BatchNormali (None, 10, 10, 1392) 5568        block6e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_activation (Acti (None, 10, 10, 1392) 0           block6e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_dwconv (DepthwiseConv2D (None, 10, 10, 1392) 34800       block6e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6e_bn (BatchNormalization) (None, 10, 10, 1392) 5568        block6e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6e_activation (Activation) (None, 10, 10, 1392) 0           block6e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_squeeze (GlobalAvera (None, 1392)         0           block6e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_excite (Multiply)    (None, 10, 10, 1392) 0           block6e_activation[0][0]         \n",
      "                                                                 block6e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_conv (Conv2D)   (None, 10, 10, 232)  322944      block6e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_bn (BatchNormal (None, 10, 10, 232)  928         block6e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6e_drop (FixedDropout)     (None, 10, 10, 232)  0           block6e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_add (Add)               (None, 10, 10, 232)  0           block6e_drop[0][0]               \n",
      "                                                                 block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_conv (Conv2D)    (None, 10, 10, 1392) 322944      block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_bn (BatchNormali (None, 10, 10, 1392) 5568        block6f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_activation (Acti (None, 10, 10, 1392) 0           block6f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_dwconv (DepthwiseConv2D (None, 10, 10, 1392) 34800       block6f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6f_bn (BatchNormalization) (None, 10, 10, 1392) 5568        block6f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6f_activation (Activation) (None, 10, 10, 1392) 0           block6f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_squeeze (GlobalAvera (None, 1392)         0           block6f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_excite (Multiply)    (None, 10, 10, 1392) 0           block6f_activation[0][0]         \n",
      "                                                                 block6f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_conv (Conv2D)   (None, 10, 10, 232)  322944      block6f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_bn (BatchNormal (None, 10, 10, 232)  928         block6f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6f_drop (FixedDropout)     (None, 10, 10, 232)  0           block6f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_add (Add)               (None, 10, 10, 232)  0           block6f_drop[0][0]               \n",
      "                                                                 block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 10, 10, 1392) 322944      block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 10, 10, 1392) 5568        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 10, 10, 1392) 0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 10, 10, 1392) 12528       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 10, 10, 1392) 5568        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 10, 10, 1392) 0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1392)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 10, 10, 1392) 0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 10, 10, 384)  534528      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 10, 10, 384)  1536        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_conv (Conv2D)    (None, 10, 10, 2304) 884736      block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_bn (BatchNormali (None, 10, 10, 2304) 9216        block7b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_activation (Acti (None, 10, 10, 2304) 0           block7b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_dwconv (DepthwiseConv2D (None, 10, 10, 2304) 20736       block7b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7b_bn (BatchNormalization) (None, 10, 10, 2304) 9216        block7b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7b_activation (Activation) (None, 10, 10, 2304) 0           block7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_squeeze (GlobalAvera (None, 2304)         0           block7b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block7b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block7b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block7b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_excite (Multiply)    (None, 10, 10, 2304) 0           block7b_activation[0][0]         \n",
      "                                                                 block7b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_conv (Conv2D)   (None, 10, 10, 384)  884736      block7b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_bn (BatchNormal (None, 10, 10, 384)  1536        block7b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_drop (FixedDropout)     (None, 10, 10, 384)  0           block7b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_add (Add)               (None, 10, 10, 384)  0           block7b_drop[0][0]               \n",
      "                                                                 block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 10, 10, 1536) 589824      block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 10, 10, 1536) 6144        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 10, 10, 1536) 0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1536)         0           top_activation[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "top_dropout (Dropout)           (None, 1536)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "probs (Dense)                   (None, 1000)         1537000     top_dropout[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 12,320,528\n",
      "Trainable params: 12,233,232\n",
      "Non-trainable params: 87,296\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 300, 300, 3)]     0         \n",
      "_________________________________________________________________\n",
      "efficientnet-b3 (Model)      (None, 1000)              12320528  \n",
      "=================================================================\n",
      "Total params: 12,320,528\n",
      "Trainable params: 12,233,232\n",
      "Non-trainable params: 87,296\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Setting New Model\n",
    "import tensorflow\n",
    "print(tensorflow.__version__)\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "import efficientnet.tfkeras as efn\n",
    "\n",
    "net = efn.EfficientNetB3( include_top=True, weights='imagenet'\n",
    "                         , input_tensor=None,input_shape=(image_shape,image_shape,3))\n",
    "net.summary()\n",
    "\n",
    "inpt = Input(shape=(image_shape, image_shape, 3))\n",
    "x = net(inpt)\n",
    "\n",
    "model = Model(inputs=[inpt], outputs=[x])\n",
    "model.summary()\n",
    "model.compile(  loss= ['sparse_categorical_crossentropy'],\n",
    "                optimizer= Adam(lr=0.0002 ,decay=1e-8),\n",
    "                metrics=['accuracy']\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting LookBack Function\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import os\n",
    "\n",
    "LR_function=ReduceLROnPlateau(\n",
    "    monitor='val_loss',                        \n",
    "    patience= 4, # 3 epochs 內acc沒下降就要調整LR\n",
    "    verbose=1,    \n",
    "    factor=0.5, # LR降為0.5\n",
    "#     min_lr=0.00000001\n",
    ")\n",
    "\n",
    "earlystop_function = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "#     min_delta= 0,  #容忍漲跌幅範圍\n",
    "    patience= 10,  #容忍不下降回合數\n",
    "    verbose= 1, \n",
    "    mode='min',\n",
    "#     baseline=None \n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "class save_best_model(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global best_loss\n",
    "        global best_acc\n",
    "        \n",
    "        if best_loss > logs['val_loss']:  \n",
    "            filepath='./Trained_model/{}Best_loss[{:.4f}].h5'.format(saving_name, best_loss)\n",
    "            try:\n",
    "                os.remove(filepath)\n",
    "            except:\n",
    "                None\n",
    "            best_loss = logs['val_loss']\n",
    "            filepath='./Trained_model/{}Best_loss[{:.4f}].h5'.format(saving_name, best_loss)\n",
    "            model.save(filepath)\n",
    "            print ('\\nSave',filepath)\n",
    "        else:\n",
    "            print ('\\nNot better loss than {:.4f}'.format(best_loss))\n",
    "            \n",
    "        if best_acc < logs['val_accuracy']:\n",
    "            filepath='./Trained_model/{}Best_acc[{:.4f}].h5'.format(saving_name, best_acc*100)\n",
    "            try:\n",
    "                os.remove(filepath)\n",
    "            except:\n",
    "                None\n",
    "            best_acc = logs['val_accuracy']\n",
    "            filepath='./Trained_model/{}Best_acc[{:.4f}].h5'.format(saving_name, best_acc*100)\n",
    "            model.save(filepath)\n",
    "            print ('Save',filepath)\n",
    "        else:\n",
    "            print ('Not better acc than {:.4f}'.format(best_acc))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Learning rate during Trainging\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_value(model.optimizer.lr, 0.0002500000118743628 )\n",
    "\n",
    "print (K.get_value(model.optimizer.lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 160.0 steps, validate for 25.0 steps\n",
      "Epoch 1/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 1.5002 - accuracy: 0.5319\n",
      "Save ./Trained_model/Mango_EfficientNetB2[6]Best_loss[0.7079].h5\n",
      "Save ./Trained_model/Mango_EfficientNetB2[6]Best_acc[67.6250].h5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 1.4948 - accuracy: 0.5330 - val_loss: 0.7079 - val_accuracy: 0.6762\n",
      "Epoch 2/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.6544 - accuracy: 0.7093\n",
      "Save ./Trained_model/Mango_EfficientNetB2[6]Best_loss[0.5212].h5\n",
      "Save ./Trained_model/Mango_EfficientNetB2[6]Best_acc[77.1250].h5\n",
      "160/160 [==============================] - 85s 530ms/step - loss: 0.6541 - accuracy: 0.7093 - val_loss: 0.5212 - val_accuracy: 0.7713\n",
      "Epoch 3/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.6009 - accuracy: 0.7362\n",
      "Not better loss than 0.5212\n",
      "Save ./Trained_model/Mango_EfficientNetB2[6]Best_acc[77.5000].h5\n",
      "160/160 [==============================] - 84s 523ms/step - loss: 0.6003 - accuracy: 0.7368 - val_loss: 0.5404 - val_accuracy: 0.7750\n",
      "Epoch 4/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5652 - accuracy: 0.7499\n",
      "Save ./Trained_model/Mango_EfficientNetB2[6]Best_loss[0.4728].h5\n",
      "Save ./Trained_model/Mango_EfficientNetB2[6]Best_acc[81.3750].h5\n",
      "160/160 [==============================] - 85s 533ms/step - loss: 0.5649 - accuracy: 0.7498 - val_loss: 0.4728 - val_accuracy: 0.8138\n",
      "Epoch 5/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5380 - accuracy: 0.7675\n",
      "Not better loss than 0.4728\n",
      "Not better acc than 0.8138\n",
      "160/160 [==============================] - 83s 517ms/step - loss: 0.5387 - accuracy: 0.7675 - val_loss: 0.5607 - val_accuracy: 0.7663\n",
      "Epoch 6/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5360 - accuracy: 0.7632\n",
      "Not better loss than 0.4728\n",
      "Not better acc than 0.8138\n",
      "160/160 [==============================] - 84s 523ms/step - loss: 0.5363 - accuracy: 0.7625 - val_loss: 0.5001 - val_accuracy: 0.7763\n",
      "Epoch 7/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5249 - accuracy: 0.7730\n",
      "Not better loss than 0.4728\n",
      "Not better acc than 0.8138\n",
      "160/160 [==============================] - 83s 519ms/step - loss: 0.5254 - accuracy: 0.7727 - val_loss: 0.5031 - val_accuracy: 0.7862\n",
      "Epoch 8/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5192 - accuracy: 0.7734\n",
      "Save ./Trained_model/Mango_EfficientNetB2[6]Best_loss[0.4149].h5\n",
      "Save ./Trained_model/Mango_EfficientNetB2[6]Best_acc[82.3750].h5\n",
      "160/160 [==============================] - 85s 532ms/step - loss: 0.5188 - accuracy: 0.7734 - val_loss: 0.4149 - val_accuracy: 0.8238\n",
      "Epoch 9/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5051 - accuracy: 0.7770\n",
      "Save ./Trained_model/Mango_EfficientNetB2[6]Best_loss[0.4110].h5\n",
      "Save ./Trained_model/Mango_EfficientNetB2[6]Best_acc[82.7500].h5\n",
      "160/160 [==============================] - 85s 532ms/step - loss: 0.5061 - accuracy: 0.7766 - val_loss: 0.4110 - val_accuracy: 0.8275\n",
      "Epoch 10/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4963 - accuracy: 0.7831\n",
      "Not better loss than 0.4110\n",
      "Not better acc than 0.8275\n",
      "160/160 [==============================] - 84s 525ms/step - loss: 0.4961 - accuracy: 0.7830 - val_loss: 0.4787 - val_accuracy: 0.7950\n",
      "Epoch 11/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4853 - accuracy: 0.7871\n",
      "Not better loss than 0.4110\n",
      "Not better acc than 0.8275\n",
      "160/160 [==============================] - 83s 517ms/step - loss: 0.4851 - accuracy: 0.7870 - val_loss: 0.4778 - val_accuracy: 0.8188\n",
      "Epoch 12/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4934 - accuracy: 0.7838\n",
      "Not better loss than 0.4110\n",
      "Not better acc than 0.8275\n",
      "160/160 [==============================] - 84s 525ms/step - loss: 0.4932 - accuracy: 0.7843 - val_loss: 0.4477 - val_accuracy: 0.8275\n",
      "Epoch 13/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4676 - accuracy: 0.7946\n",
      "Not better loss than 0.4110\n",
      "Not better acc than 0.8275\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n",
      "160/160 [==============================] - 83s 521ms/step - loss: 0.4673 - accuracy: 0.7950 - val_loss: 0.4285 - val_accuracy: 0.8238\n",
      "Epoch 14/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4445 - accuracy: 0.8047\n",
      "Not better loss than 0.4110\n",
      "Save ./Trained_model/Mango_EfficientNetB2[6]Best_acc[83.1250].h5\n",
      "160/160 [==============================] - 84s 528ms/step - loss: 0.4454 - accuracy: 0.8046 - val_loss: 0.4352 - val_accuracy: 0.8313\n",
      "Epoch 15/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4415 - accuracy: 0.8106\n",
      "Not better loss than 0.4110\n",
      "Not better acc than 0.8313\n",
      "160/160 [==============================] - 84s 526ms/step - loss: 0.4411 - accuracy: 0.8109 - val_loss: 0.4226 - val_accuracy: 0.8288\n",
      "Epoch 16/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4226 - accuracy: 0.8180\n",
      "Not better loss than 0.4110\n",
      "Not better acc than 0.8313\n",
      "160/160 [==============================] - 84s 522ms/step - loss: 0.4229 - accuracy: 0.8173 - val_loss: 0.4400 - val_accuracy: 0.8188\n",
      "Epoch 17/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4219 - accuracy: 0.8171\n",
      "Not better loss than 0.4110\n",
      "Save ./Trained_model/Mango_EfficientNetB2[6]Best_acc[83.2500].h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "160/160 [==============================] - 84s 526ms/step - loss: 0.4213 - accuracy: 0.8173 - val_loss: 0.4153 - val_accuracy: 0.8325\n",
      "Epoch 18/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4037 - accuracy: 0.8255\n",
      "Not better loss than 0.4110\n",
      "Not better acc than 0.8325\n",
      "160/160 [==============================] - 83s 520ms/step - loss: 0.4036 - accuracy: 0.8252 - val_loss: 0.4379 - val_accuracy: 0.8325\n",
      "Epoch 19/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4137 - accuracy: 0.8169\n",
      "Not better loss than 0.4110\n",
      "Save ./Trained_model/Mango_EfficientNetB2[6]Best_acc[83.7500].h5\n",
      "Restoring model weights from the end of the best epoch.\n",
      "160/160 [==============================] - 84s 523ms/step - loss: 0.4147 - accuracy: 0.8157 - val_loss: 0.4366 - val_accuracy: 0.8375\n",
      "Epoch 00019: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 160.0 steps, validate for 25.0 steps\n",
      "Epoch 1/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 1.4520 - accuracy: 0.5615\n",
      "Save ./Trained_model/Mango_EfficientNetB2[7]Best_loss[0.6711].h5\n",
      "Save ./Trained_model/Mango_EfficientNetB2[7]Best_acc[73.1250].h5\n",
      "160/160 [==============================] - 98s 615ms/step - loss: 1.4474 - accuracy: 0.5623 - val_loss: 0.6711 - val_accuracy: 0.7312\n",
      "Epoch 2/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.6491 - accuracy: 0.7139\n",
      "Save ./Trained_model/Mango_EfficientNetB2[7]Best_loss[0.5297].h5\n",
      "Save ./Trained_model/Mango_EfficientNetB2[7]Best_acc[77.6250].h5\n",
      "160/160 [==============================] - 85s 529ms/step - loss: 0.6479 - accuracy: 0.7146 - val_loss: 0.5297 - val_accuracy: 0.7763\n",
      "Epoch 3/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5914 - accuracy: 0.7405\n",
      "Save ./Trained_model/Mango_EfficientNetB2[7]Best_loss[0.4995].h5\n",
      "Not better acc than 0.7763\n",
      "160/160 [==============================] - 83s 520ms/step - loss: 0.5910 - accuracy: 0.7409 - val_loss: 0.4995 - val_accuracy: 0.7713\n",
      "Epoch 4/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5695 - accuracy: 0.7473\n",
      "Save ./Trained_model/Mango_EfficientNetB2[7]Best_loss[0.4536].h5\n",
      "Save ./Trained_model/Mango_EfficientNetB2[7]Best_acc[81.0000].h5\n",
      "160/160 [==============================] - 85s 529ms/step - loss: 0.5705 - accuracy: 0.7475 - val_loss: 0.4536 - val_accuracy: 0.8100\n",
      "Epoch 5/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5495 - accuracy: 0.7626\n",
      "Not better loss than 0.4536\n",
      "Not better acc than 0.8100\n",
      "160/160 [==============================] - 82s 515ms/step - loss: 0.5494 - accuracy: 0.7629 - val_loss: 0.4743 - val_accuracy: 0.8037\n",
      "Epoch 6/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5280 - accuracy: 0.7673\n",
      "Not better loss than 0.4536\n",
      "Not better acc than 0.8100\n",
      "160/160 [==============================] - 82s 514ms/step - loss: 0.5273 - accuracy: 0.7673 - val_loss: 0.4539 - val_accuracy: 0.8050\n",
      "Epoch 7/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5162 - accuracy: 0.7783\n",
      "Not better loss than 0.4536\n",
      "Not better acc than 0.8100\n",
      "160/160 [==============================] - 83s 519ms/step - loss: 0.5165 - accuracy: 0.7782 - val_loss: 0.4964 - val_accuracy: 0.7925\n",
      "Epoch 8/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5200 - accuracy: 0.7739\n",
      "Save ./Trained_model/Mango_EfficientNetB2[7]Best_loss[0.4455].h5\n",
      "Save ./Trained_model/Mango_EfficientNetB2[7]Best_acc[81.3750].h5\n",
      "160/160 [==============================] - 84s 525ms/step - loss: 0.5202 - accuracy: 0.7734 - val_loss: 0.4455 - val_accuracy: 0.8138\n",
      "Epoch 9/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4931 - accuracy: 0.7838\n",
      "Not better loss than 0.4455\n",
      "Save ./Trained_model/Mango_EfficientNetB2[7]Best_acc[81.7500].h5\n",
      "160/160 [==============================] - 84s 523ms/step - loss: 0.4930 - accuracy: 0.7837 - val_loss: 0.4567 - val_accuracy: 0.8175\n",
      "Epoch 10/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4844 - accuracy: 0.7892\n",
      "Save ./Trained_model/Mango_EfficientNetB2[7]Best_loss[0.4340].h5\n",
      "Not better acc than 0.8175\n",
      "160/160 [==============================] - 84s 524ms/step - loss: 0.4842 - accuracy: 0.7889 - val_loss: 0.4340 - val_accuracy: 0.8175\n",
      "Epoch 11/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4759 - accuracy: 0.7898\n",
      "Save ./Trained_model/Mango_EfficientNetB2[7]Best_loss[0.4325].h5\n",
      "Not better acc than 0.8175\n",
      "160/160 [==============================] - 84s 523ms/step - loss: 0.4773 - accuracy: 0.7896 - val_loss: 0.4325 - val_accuracy: 0.8138\n",
      "Epoch 12/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4761 - accuracy: 0.7941\n",
      "Save ./Trained_model/Mango_EfficientNetB2[7]Best_loss[0.4291].h5\n",
      "Save ./Trained_model/Mango_EfficientNetB2[7]Best_acc[83.1250].h5\n",
      "160/160 [==============================] - 84s 525ms/step - loss: 0.4767 - accuracy: 0.7937 - val_loss: 0.4291 - val_accuracy: 0.8313\n",
      "Epoch 13/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4544 - accuracy: 0.8052\n",
      "Save ./Trained_model/Mango_EfficientNetB2[7]Best_loss[0.4201].h5\n",
      "Save ./Trained_model/Mango_EfficientNetB2[7]Best_acc[83.7500].h5\n",
      "160/160 [==============================] - 85s 533ms/step - loss: 0.4533 - accuracy: 0.8055 - val_loss: 0.4201 - val_accuracy: 0.8375\n",
      "Epoch 14/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4538 - accuracy: 0.7960\n",
      "Not better loss than 0.4201\n",
      "Not better acc than 0.8375\n",
      "160/160 [==============================] - 82s 512ms/step - loss: 0.4530 - accuracy: 0.7962 - val_loss: 0.4257 - val_accuracy: 0.8313\n",
      "Epoch 15/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4455 - accuracy: 0.8065\n",
      "Save ./Trained_model/Mango_EfficientNetB2[7]Best_loss[0.4033].h5\n",
      "Not better acc than 0.8375\n",
      "160/160 [==============================] - 84s 522ms/step - loss: 0.4455 - accuracy: 0.8061 - val_loss: 0.4033 - val_accuracy: 0.8350\n",
      "Epoch 16/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4406 - accuracy: 0.8088\n",
      "Not better loss than 0.4033\n",
      "Not better acc than 0.8375\n",
      "160/160 [==============================] - 83s 519ms/step - loss: 0.4408 - accuracy: 0.8086 - val_loss: 0.4482 - val_accuracy: 0.8213\n",
      "Epoch 17/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4336 - accuracy: 0.8169\n",
      "Not better loss than 0.4033\n",
      "Not better acc than 0.8375\n",
      "160/160 [==============================] - 83s 517ms/step - loss: 0.4326 - accuracy: 0.8171 - val_loss: 0.4581 - val_accuracy: 0.8338\n",
      "Epoch 18/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4301 - accuracy: 0.8183\n",
      "Not better loss than 0.4033\n",
      "Not better acc than 0.8375\n",
      "160/160 [==============================] - 82s 513ms/step - loss: 0.4309 - accuracy: 0.8180 - val_loss: 0.4442 - val_accuracy: 0.8275\n",
      "Epoch 19/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4169 - accuracy: 0.8181\n",
      "Not better loss than 0.4033\n",
      "Not better acc than 0.8375\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n",
      "160/160 [==============================] - 83s 521ms/step - loss: 0.4158 - accuracy: 0.8188 - val_loss: 0.4265 - val_accuracy: 0.8313\n",
      "Epoch 20/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3907 - accuracy: 0.8374\n",
      "Not better loss than 0.4033\n",
      "Not better acc than 0.8375\n",
      "160/160 [==============================] - 83s 518ms/step - loss: 0.3917 - accuracy: 0.8366 - val_loss: 0.4539 - val_accuracy: 0.8263\n",
      "Epoch 21/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3777 - accuracy: 0.8379\n",
      "Not better loss than 0.4033\n",
      "Not better acc than 0.8375\n",
      "160/160 [==============================] - 82s 515ms/step - loss: 0.3780 - accuracy: 0.8375 - val_loss: 0.4519 - val_accuracy: 0.8275\n",
      "Epoch 22/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3812 - accuracy: 0.8392\n",
      "Not better loss than 0.4033\n",
      "Not better acc than 0.8375\n",
      "160/160 [==============================] - 83s 520ms/step - loss: 0.3808 - accuracy: 0.8398 - val_loss: 0.4695 - val_accuracy: 0.8275\n",
      "Epoch 23/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3755 - accuracy: 0.8422\n",
      "Not better loss than 0.4033\n",
      "Not better acc than 0.8375\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "160/160 [==============================] - 82s 515ms/step - loss: 0.3748 - accuracy: 0.8429 - val_loss: 0.4640 - val_accuracy: 0.8087\n",
      "Epoch 24/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3499 - accuracy: 0.8534\n",
      "Not better loss than 0.4033\n",
      "Not better acc than 0.8375\n",
      "160/160 [==============================] - 82s 515ms/step - loss: 0.3494 - accuracy: 0.8534 - val_loss: 0.4540 - val_accuracy: 0.8350\n",
      "Epoch 25/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3510 - accuracy: 0.8535\n",
      "Not better loss than 0.4033\n",
      "Not better acc than 0.8375\n",
      "Restoring model weights from the end of the best epoch.\n",
      "160/160 [==============================] - 83s 518ms/step - loss: 0.3504 - accuracy: 0.8539 - val_loss: 0.4793 - val_accuracy: 0.8200\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 160.0 steps, validate for 25.0 steps\n",
      "Epoch 1/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 1.4279 - accuracy: 0.5709\n",
      "Save ./Trained_model/Mango_EfficientNetB2[8]Best_loss[0.6839].h5\n",
      "Save ./Trained_model/Mango_EfficientNetB2[8]Best_acc[71.3750].h5\n",
      "160/160 [==============================] - 99s 617ms/step - loss: 1.4236 - accuracy: 0.5716 - val_loss: 0.6839 - val_accuracy: 0.7138\n",
      "Epoch 2/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.6420 - accuracy: 0.7184\n",
      "Save ./Trained_model/Mango_EfficientNetB2[8]Best_loss[0.5321].h5\n",
      "Save ./Trained_model/Mango_EfficientNetB2[8]Best_acc[77.2500].h5\n",
      "160/160 [==============================] - 83s 521ms/step - loss: 0.6418 - accuracy: 0.7189 - val_loss: 0.5321 - val_accuracy: 0.7725\n",
      "Epoch 3/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5930 - accuracy: 0.7353\n",
      "Save ./Trained_model/Mango_EfficientNetB2[8]Best_loss[0.5188].h5\n",
      "Save ./Trained_model/Mango_EfficientNetB2[8]Best_acc[78.1250].h5\n",
      "160/160 [==============================] - 83s 520ms/step - loss: 0.5934 - accuracy: 0.7354 - val_loss: 0.5188 - val_accuracy: 0.7812\n",
      "Epoch 4/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5552 - accuracy: 0.7482\n",
      "Save ./Trained_model/Mango_EfficientNetB2[8]Best_loss[0.4459].h5\n",
      "Save ./Trained_model/Mango_EfficientNetB2[8]Best_acc[80.8750].h5\n",
      "160/160 [==============================] - 83s 522ms/step - loss: 0.5556 - accuracy: 0.7484 - val_loss: 0.4459 - val_accuracy: 0.8087\n",
      "Epoch 5/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5459 - accuracy: 0.7626\n",
      "Not better loss than 0.4459\n",
      "Not better acc than 0.8087\n",
      "160/160 [==============================] - 82s 512ms/step - loss: 0.5466 - accuracy: 0.7625 - val_loss: 0.6083 - val_accuracy: 0.7362\n",
      "Epoch 6/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5293 - accuracy: 0.7704\n",
      "Not better loss than 0.4459\n",
      "Not better acc than 0.8087\n",
      "160/160 [==============================] - 82s 513ms/step - loss: 0.5291 - accuracy: 0.7707 - val_loss: 0.4958 - val_accuracy: 0.7800\n",
      "Epoch 7/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5139 - accuracy: 0.7741\n",
      "Save ./Trained_model/Mango_EfficientNetB2[8]Best_loss[0.4386].h5\n",
      "Save ./Trained_model/Mango_EfficientNetB2[8]Best_acc[81.6250].h5\n",
      "160/160 [==============================] - 83s 521ms/step - loss: 0.5148 - accuracy: 0.7734 - val_loss: 0.4386 - val_accuracy: 0.8163\n",
      "Epoch 8/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5097 - accuracy: 0.7752\n",
      "Not better loss than 0.4386\n",
      "Not better acc than 0.8163\n",
      "160/160 [==============================] - 82s 513ms/step - loss: 0.5097 - accuracy: 0.7748 - val_loss: 0.4568 - val_accuracy: 0.8112\n",
      "Epoch 9/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5059 - accuracy: 0.7757\n",
      "Not better loss than 0.4386\n",
      "Not better acc than 0.8163\n",
      "160/160 [==============================] - 82s 510ms/step - loss: 0.5056 - accuracy: 0.7757 - val_loss: 0.4636 - val_accuracy: 0.8037\n",
      "Epoch 10/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4846 - accuracy: 0.7890\n",
      "Not better loss than 0.4386\n",
      "Not better acc than 0.8163\n",
      "160/160 [==============================] - 82s 510ms/step - loss: 0.4847 - accuracy: 0.7889 - val_loss: 0.4939 - val_accuracy: 0.7800\n",
      "Epoch 11/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4851 - accuracy: 0.7851\n",
      "Not better loss than 0.4386\n",
      "Not better acc than 0.8163\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n",
      "160/160 [==============================] - 82s 511ms/step - loss: 0.4862 - accuracy: 0.7846 - val_loss: 0.5102 - val_accuracy: 0.7688\n",
      "Epoch 12/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4558 - accuracy: 0.8022\n",
      "Save ./Trained_model/Mango_EfficientNetB2[8]Best_loss[0.4188].h5\n",
      "Save ./Trained_model/Mango_EfficientNetB2[8]Best_acc[82.2500].h5\n",
      "160/160 [==============================] - 83s 520ms/step - loss: 0.4545 - accuracy: 0.8027 - val_loss: 0.4188 - val_accuracy: 0.8225\n",
      "Epoch 13/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4600 - accuracy: 0.7957\n",
      "Not better loss than 0.4188\n",
      "Not better acc than 0.8225\n",
      "160/160 [==============================] - 82s 510ms/step - loss: 0.4594 - accuracy: 0.7961 - val_loss: 0.4577 - val_accuracy: 0.8075\n",
      "Epoch 14/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4408 - accuracy: 0.8077\n",
      "Not better loss than 0.4188\n",
      "Not better acc than 0.8225\n",
      "160/160 [==============================] - 82s 512ms/step - loss: 0.4407 - accuracy: 0.8079 - val_loss: 0.4260 - val_accuracy: 0.8125\n",
      "Epoch 15/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4271 - accuracy: 0.8156\n",
      "Not better loss than 0.4188\n",
      "Not better acc than 0.8225\n",
      "160/160 [==============================] - 82s 511ms/step - loss: 0.4274 - accuracy: 0.8155 - val_loss: 0.4833 - val_accuracy: 0.7887\n",
      "Epoch 16/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4302 - accuracy: 0.8072\n",
      "Not better loss than 0.4188\n",
      "Not better acc than 0.8225\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "160/160 [==============================] - 82s 514ms/step - loss: 0.4296 - accuracy: 0.8079 - val_loss: 0.5219 - val_accuracy: 0.7738\n",
      "Epoch 17/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4135 - accuracy: 0.8244\n",
      "Not better loss than 0.4188\n",
      "Save ./Trained_model/Mango_EfficientNetB2[8]Best_acc[82.5000].h5\n",
      "160/160 [==============================] - 82s 516ms/step - loss: 0.4143 - accuracy: 0.8232 - val_loss: 0.4350 - val_accuracy: 0.8250\n",
      "Epoch 18/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4110 - accuracy: 0.8214\n",
      "Not better loss than 0.4188\n",
      "Not better acc than 0.8250\n",
      "160/160 [==============================] - 82s 511ms/step - loss: 0.4104 - accuracy: 0.8214 - val_loss: 0.4315 - val_accuracy: 0.8163\n",
      "Epoch 19/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3920 - accuracy: 0.8343\n",
      "Not better loss than 0.4188\n",
      "Save ./Trained_model/Mango_EfficientNetB2[8]Best_acc[82.7500].h5\n",
      "160/160 [==============================] - 83s 522ms/step - loss: 0.3925 - accuracy: 0.8343 - val_loss: 0.4279 - val_accuracy: 0.8275\n",
      "Epoch 20/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3995 - accuracy: 0.8300\n",
      "Not better loss than 0.4188\n",
      "Not better acc than 0.8275\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "160/160 [==============================] - 82s 513ms/step - loss: 0.3993 - accuracy: 0.8302 - val_loss: 0.4336 - val_accuracy: 0.8213\n",
      "Epoch 21/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3933 - accuracy: 0.8280\n",
      "Not better loss than 0.4188\n",
      "Not better acc than 0.8275\n",
      "160/160 [==============================] - 82s 514ms/step - loss: 0.3935 - accuracy: 0.8279 - val_loss: 0.4375 - val_accuracy: 0.8175\n",
      "Epoch 22/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8336\n",
      "Save ./Trained_model/Mango_EfficientNetB2[8]Best_loss[0.4161].h5\n",
      "Not better acc than 0.8275\n",
      "160/160 [==============================] - 83s 516ms/step - loss: 0.3860 - accuracy: 0.8332 - val_loss: 0.4161 - val_accuracy: 0.8263\n",
      "Epoch 23/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8325\n",
      "Not better loss than 0.4161\n",
      "Not better acc than 0.8275\n",
      "160/160 [==============================] - 82s 512ms/step - loss: 0.3815 - accuracy: 0.8329 - val_loss: 0.4220 - val_accuracy: 0.8263\n",
      "Epoch 24/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8309\n",
      "Not better loss than 0.4161\n",
      "Not better acc than 0.8275\n",
      "160/160 [==============================] - 82s 513ms/step - loss: 0.3846 - accuracy: 0.8311 - val_loss: 0.4564 - val_accuracy: 0.8112\n",
      "Epoch 25/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3751 - accuracy: 0.8374\n",
      "Not better loss than 0.4161\n",
      "Not better acc than 0.8275\n",
      "160/160 [==============================] - 82s 512ms/step - loss: 0.3750 - accuracy: 0.8377 - val_loss: 0.4426 - val_accuracy: 0.8125\n",
      "Epoch 26/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3793 - accuracy: 0.8381\n",
      "Not better loss than 0.4161\n",
      "Not better acc than 0.8275\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "160/160 [==============================] - 81s 509ms/step - loss: 0.3787 - accuracy: 0.8384 - val_loss: 0.4560 - val_accuracy: 0.8188\n",
      "Epoch 27/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3688 - accuracy: 0.8410\n",
      "Not better loss than 0.4161\n",
      "Not better acc than 0.8275\n",
      "160/160 [==============================] - 82s 513ms/step - loss: 0.3685 - accuracy: 0.8409 - val_loss: 0.4527 - val_accuracy: 0.8175\n",
      "Epoch 28/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8392\n",
      "Not better loss than 0.4161\n",
      "Not better acc than 0.8275\n",
      "160/160 [==============================] - 82s 511ms/step - loss: 0.3834 - accuracy: 0.8395 - val_loss: 0.4545 - val_accuracy: 0.8188\n",
      "Epoch 29/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3703 - accuracy: 0.8444\n",
      "Not better loss than 0.4161\n",
      "Not better acc than 0.8275\n",
      "160/160 [==============================] - 82s 513ms/step - loss: 0.3699 - accuracy: 0.8446 - val_loss: 0.4454 - val_accuracy: 0.8062\n",
      "Epoch 30/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3686 - accuracy: 0.8429\n",
      "Not better loss than 0.4161\n",
      "Not better acc than 0.8275\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "160/160 [==============================] - 82s 510ms/step - loss: 0.3683 - accuracy: 0.8430 - val_loss: 0.4581 - val_accuracy: 0.8087\n",
      "Epoch 31/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3665 - accuracy: 0.8447\n",
      "Not better loss than 0.4161\n",
      "Not better acc than 0.8275\n",
      "160/160 [==============================] - 82s 512ms/step - loss: 0.3667 - accuracy: 0.8450 - val_loss: 0.4558 - val_accuracy: 0.8112\n",
      "Epoch 32/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3561 - accuracy: 0.8446\n",
      "Not better loss than 0.4161\n",
      "Not better acc than 0.8275\n",
      "Restoring model weights from the end of the best epoch.\n",
      "160/160 [==============================] - 82s 514ms/step - loss: 0.3586 - accuracy: 0.8439 - val_loss: 0.4622 - val_accuracy: 0.8112\n",
      "Epoch 00032: early stopping\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 160.0 steps, validate for 25.0 steps\n",
      "Epoch 1/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 1.4764 - accuracy: 0.5522\n",
      "Save ./Trained_model/Mango_EfficientNetB2[9]Best_loss[0.6885].h5\n",
      "Save ./Trained_model/Mango_EfficientNetB2[9]Best_acc[71.7500].h5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 1.4707 - accuracy: 0.5534 - val_loss: 0.6885 - val_accuracy: 0.7175\n",
      "Epoch 2/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.6532 - accuracy: 0.7173\n",
      "Save ./Trained_model/Mango_EfficientNetB2[9]Best_loss[0.5819].h5\n",
      "Save ./Trained_model/Mango_EfficientNetB2[9]Best_acc[76.5000].h5\n",
      "160/160 [==============================] - 86s 538ms/step - loss: 0.6535 - accuracy: 0.7173 - val_loss: 0.5819 - val_accuracy: 0.7650\n",
      "Epoch 3/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5970 - accuracy: 0.7375\n",
      "Save ./Trained_model/Mango_EfficientNetB2[9]Best_loss[0.4788].h5\n",
      "Save ./Trained_model/Mango_EfficientNetB2[9]Best_acc[80.2500].h5\n",
      "160/160 [==============================] - 85s 532ms/step - loss: 0.5971 - accuracy: 0.7375 - val_loss: 0.4788 - val_accuracy: 0.8025\n",
      "Epoch 4/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5663 - accuracy: 0.7556\n",
      "Not better loss than 0.4788\n",
      "Not better acc than 0.8025\n",
      "160/160 [==============================] - 84s 522ms/step - loss: 0.5667 - accuracy: 0.7559 - val_loss: 0.5003 - val_accuracy: 0.7700\n",
      "Epoch 5/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5478 - accuracy: 0.7644\n",
      "Save ./Trained_model/Mango_EfficientNetB2[9]Best_loss[0.4232].h5\n",
      "Save ./Trained_model/Mango_EfficientNetB2[9]Best_acc[82.6250].h5\n",
      "160/160 [==============================] - 86s 538ms/step - loss: 0.5475 - accuracy: 0.7645 - val_loss: 0.4232 - val_accuracy: 0.8263\n",
      "Epoch 6/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5332 - accuracy: 0.7695\n",
      "Not better loss than 0.4232\n",
      "Not better acc than 0.8263\n",
      "160/160 [==============================] - 84s 528ms/step - loss: 0.5331 - accuracy: 0.7693 - val_loss: 0.4691 - val_accuracy: 0.8062\n",
      "Epoch 7/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5289 - accuracy: 0.7660\n",
      "Not better loss than 0.4232\n",
      "Not better acc than 0.8263\n",
      "160/160 [==============================] - 84s 523ms/step - loss: 0.5291 - accuracy: 0.7657 - val_loss: 0.4561 - val_accuracy: 0.8012\n",
      "Epoch 8/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.5129 - accuracy: 0.7775\n",
      "Not better loss than 0.4232\n",
      "Not better acc than 0.8263\n",
      "160/160 [==============================] - 84s 526ms/step - loss: 0.5119 - accuracy: 0.7779 - val_loss: 0.4486 - val_accuracy: 0.8112\n",
      "Epoch 9/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4948 - accuracy: 0.7827\n",
      "Not better loss than 0.4232\n",
      "Not better acc than 0.8263\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n",
      "160/160 [==============================] - 84s 523ms/step - loss: 0.4939 - accuracy: 0.7836 - val_loss: 0.5366 - val_accuracy: 0.7763\n",
      "Epoch 10/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4812 - accuracy: 0.7858\n",
      "Not better loss than 0.4232\n",
      "Not better acc than 0.8263\n",
      "160/160 [==============================] - 84s 522ms/step - loss: 0.4817 - accuracy: 0.7852 - val_loss: 0.4311 - val_accuracy: 0.8225\n",
      "Epoch 11/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4733 - accuracy: 0.7953\n",
      "Save ./Trained_model/Mango_EfficientNetB2[9]Best_loss[0.4217].h5\n",
      "Save ./Trained_model/Mango_EfficientNetB2[9]Best_acc[82.7500].h5\n",
      "160/160 [==============================] - 86s 538ms/step - loss: 0.4742 - accuracy: 0.7948 - val_loss: 0.4217 - val_accuracy: 0.8275\n",
      "Epoch 12/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4514 - accuracy: 0.8032\n",
      "Not better loss than 0.4217\n",
      "Not better acc than 0.8275\n",
      "160/160 [==============================] - 84s 523ms/step - loss: 0.4520 - accuracy: 0.8029 - val_loss: 0.4558 - val_accuracy: 0.8087\n",
      "Epoch 13/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4480 - accuracy: 0.8070\n",
      "Not better loss than 0.4217\n",
      "Save ./Trained_model/Mango_EfficientNetB2[9]Best_acc[83.0000].h5\n",
      "160/160 [==============================] - 84s 527ms/step - loss: 0.4473 - accuracy: 0.8077 - val_loss: 0.4274 - val_accuracy: 0.8300\n",
      "Epoch 14/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4421 - accuracy: 0.8045\n",
      "Save ./Trained_model/Mango_EfficientNetB2[9]Best_loss[0.4121].h5\n",
      "Not better acc than 0.8300\n",
      "160/160 [==============================] - 85s 529ms/step - loss: 0.4421 - accuracy: 0.8048 - val_loss: 0.4121 - val_accuracy: 0.8163\n",
      "Epoch 15/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4297 - accuracy: 0.8090\n",
      "Not better loss than 0.4121\n",
      "Not better acc than 0.8300\n",
      "160/160 [==============================] - 84s 526ms/step - loss: 0.4314 - accuracy: 0.8084 - val_loss: 0.4496 - val_accuracy: 0.8087\n",
      "Epoch 16/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4380 - accuracy: 0.8084\n",
      "Not better loss than 0.4121\n",
      "Not better acc than 0.8300\n",
      "160/160 [==============================] - 84s 522ms/step - loss: 0.4389 - accuracy: 0.8077 - val_loss: 0.4381 - val_accuracy: 0.8288\n",
      "Epoch 17/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4368 - accuracy: 0.8104\n",
      "Not better loss than 0.4121\n",
      "Not better acc than 0.8300\n",
      "160/160 [==============================] - 84s 524ms/step - loss: 0.4364 - accuracy: 0.8107 - val_loss: 0.4822 - val_accuracy: 0.8037\n",
      "Epoch 18/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4303 - accuracy: 0.8147\n",
      "Not better loss than 0.4121\n",
      "Not better acc than 0.8300\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "160/160 [==============================] - 84s 525ms/step - loss: 0.4305 - accuracy: 0.8143 - val_loss: 0.4640 - val_accuracy: 0.8188\n",
      "Epoch 19/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4060 - accuracy: 0.8289\n",
      "Not better loss than 0.4121\n",
      "Not better acc than 0.8300\n",
      "160/160 [==============================] - 83s 520ms/step - loss: 0.4053 - accuracy: 0.8289 - val_loss: 0.4392 - val_accuracy: 0.8188\n",
      "Epoch 20/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3982 - accuracy: 0.8298\n",
      "Not better loss than 0.4121\n",
      "Not better acc than 0.8300\n",
      "160/160 [==============================] - 84s 526ms/step - loss: 0.3980 - accuracy: 0.8300 - val_loss: 0.4593 - val_accuracy: 0.8188\n",
      "Epoch 21/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3908 - accuracy: 0.8291\n",
      "Not better loss than 0.4121\n",
      "Not better acc than 0.8300\n",
      "160/160 [==============================] - 84s 527ms/step - loss: 0.3919 - accuracy: 0.8286 - val_loss: 0.4540 - val_accuracy: 0.8225\n",
      "Epoch 22/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.8295\n",
      "Not better loss than 0.4121\n",
      "Not better acc than 0.8300\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "160/160 [==============================] - 84s 523ms/step - loss: 0.3881 - accuracy: 0.8293 - val_loss: 0.4803 - val_accuracy: 0.8188\n",
      "Epoch 23/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3787 - accuracy: 0.8356\n",
      "Not better loss than 0.4121\n",
      "Save ./Trained_model/Mango_EfficientNetB2[9]Best_acc[83.8750].h5\n",
      "160/160 [==============================] - 85s 528ms/step - loss: 0.3782 - accuracy: 0.8355 - val_loss: 0.4527 - val_accuracy: 0.8388\n",
      "Epoch 24/300\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.3687 - accuracy: 0.8447\n",
      "Not better loss than 0.4121\n",
      "Not better acc than 0.8388\n",
      "Restoring model weights from the end of the best epoch.\n",
      "160/160 [==============================] - 84s 525ms/step - loss: 0.3690 - accuracy: 0.8448 - val_loss: 0.4620 - val_accuracy: 0.8225\n",
      "Epoch 00024: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Training Model\n",
    "for i in range(6,10):\n",
    "    saving_name = 'Mango_EfficientNetB2[{}]'.format(i)\n",
    "################\n",
    "\n",
    "    import tensorflow as tf\n",
    "    best_loss = 100.\n",
    "    best_acc = 0.\n",
    "    tf.keras.backend.clear_session()\n",
    "    net = efn.EfficientNetB2( include_top=True, weights='imagenet'\n",
    "                         , input_tensor=None,input_shape=(image_shape,image_shape,3))\n",
    "    inpt = Input(shape=(image_shape, image_shape, 3))\n",
    "    x = net(inpt)\n",
    "    model = Model(inputs=[inpt], outputs=[x])\n",
    "    model.compile(  loss= ['sparse_categorical_crossentropy'],\n",
    "                optimizer= Adam(lr=0.0002 ,decay=1e-8),\n",
    "                metrics=['accuracy']\n",
    "                )\n",
    "\n",
    "    model.fit(traingen.flow(X_train,y_train,batch_size=35), \n",
    "                    steps_per_epoch=X_train.shape[0]/35 , epochs=300, shuffle = True,\n",
    "                    validation_data=testgen.flow(X_test,y_test,batch_size=32,shuffle=False),\n",
    "                    validation_steps=X_test.shape[0]/32,\n",
    "                    callbacks=[save_best_model(), LR_function, \n",
    "                               earlystop_function],\n",
    "                    workers = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "175/175 [==============================] - 32s 180ms/step - loss: 0.2815 - accuracy: 0.8791\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "25/25 [==============================] - 4s 168ms/step - loss: 0.3954 - accuracy: 0.8400\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model Score\n",
    "batch_size = 32\n",
    "\n",
    "#########################\n",
    "score = model.evaluate(testgen.flow(X_train,y_train,batch_size=batch_size,shuffle=False)\n",
    "                      ,steps = X_train.shape[0]/batch_size)\n",
    "# print (score)\n",
    "# score = model.evaluate(X_train/255.,y_train)\n",
    "# print (score)\n",
    "score = model.evaluate(testgen.flow(X_test,y_test,batch_size=batch_size,shuffle=False)\n",
    "                       ,steps = X_test.shape[0]/batch_size)\n",
    "# print (score)\n",
    "# score = model.evaluate(X_test/255.,y_test)\n",
    "# print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Model\n",
    "model_name = 'adi_B3[5]Best_loss[0.3885].h5'\n",
    "saving_path = './Model/'+ model_name +'.h5'\n",
    "\n",
    "#################################\n",
    "model.save(saving_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Test Data\n",
    "\n",
    "test_data = np.load('./mango_test_data.npy',allow_pickle=True)\n",
    "test_name = np.load('./mango_test_name.npy',allow_pickle=True)\n",
    "test_data = resize_mango(test_data,image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Test Result\n",
    "\n",
    "ans = model.predict(testgen.flow(test_data,batch_size=batch_size,shuffle=False))\n",
    "# ans = model.predict(test_data/255.)\n",
    "\n",
    "np.save('./Predict/' + model_name + 'predict.npy',ans[:,1:4])\n",
    "\n",
    "ans = np.argmax(ans, axis=1)\n",
    "ans = list(ans)\n",
    "\n",
    "output = list()\n",
    "output.append (['image_id', 'label'])\n",
    "for idx,data in enumerate(ans):\n",
    "    if ans[idx] == 1:\n",
    "        label = 'A'\n",
    "    if ans[idx] == 2:\n",
    "        label = 'B'\n",
    "    if ans[idx] == 3:\n",
    "        label = 'C'\n",
    "    output.append([test_name[idx],label])\n",
    "\n",
    "import csv\n",
    "\n",
    "with open( './Result/' + model_name + 'ans.csv', 'w', newline='') as csvfile:\n",
    "  writer = csv.writer(csvfile)\n",
    "  writer.writerows(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "\n",
    "saving_name = ''\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('./Trained_model/Mango_EfficientNetB3[5]Best_loss[0.3885].h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
