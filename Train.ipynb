{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "image_shape = 300\n",
    "\n",
    "import numpy as np\n",
    "X_train = np.load('./mango_train_data.npy',allow_pickle=True)\n",
    "X_test = np.load('./mango_dev_data.npy',allow_pickle=True)\n",
    "\n",
    "import cv2\n",
    "def resize_mango(mango_data, size):\n",
    "    res_mango = list()\n",
    "    for mango in mango_data:\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        large_size = max(int(np.shape(mango)[0]),int(np.shape(mango)[1]))\n",
    "        mango = cv2.copyMakeBorder(mango,int((large_size-np.shape(mango)[0])/2),int((large_size-np.shape(mango)[0])/2)\n",
    "                               ,int((large_size-np.shape(mango)[1])/2),int((large_size-np.shape(mango)[1])/2)\n",
    "                               ,cv2.BORDER_REPLICATE)\n",
    "        res_mango.append(cv2.resize(mango,(size,size),interpolation = cv2.INTER_CUBIC))    \n",
    "#     np.save('./res_{}_mango({}).npy'.format(name,size),res_mango)\n",
    "    return np.array(res_mango)\n",
    "\n",
    "X_train = resize_mango(X_train,image_shape)\n",
    "y_train = np.load('./mango_train_label.npy',allow_pickle=True)\n",
    "X_test = resize_mango(X_test,image_shape)\n",
    "y_test = np.load('./mango_dev_label.npy',allow_pickle=True)\n",
    "\n",
    "print (np.shape(X_train))\n",
    "print (np.shape(y_train))\n",
    "print (np.shape(X_test))\n",
    "print (np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Data Generator\n",
    "import Augmentor\n",
    "\n",
    "train = Augmentor.Pipeline()\n",
    "\n",
    "train.random_brightness(probability=0.6, min_factor=0.9, max_factor=1.2)\n",
    "train.random_color(probability=0.6, min_factor=0.9, max_factor=1.2)\n",
    "train.random_contrast(probability=0.6, min_factor=0.95, max_factor=1.1)\n",
    "train.random_distortion(probability=0.5, grid_width=4, grid_height=8, magnitude=6)\n",
    "train.skew(probability=0.8, magnitude=0.5)\n",
    "train.shear(probability=0.7, max_shear_left=20, max_shear_right=20)\n",
    "train.zoom(probability=0.5, min_factor=1.1, max_factor=1.3)\n",
    "train.rotate(probability=1, max_left_rotation=24, max_right_rotation=24)\n",
    "train.rotate_random_90(0.75)\n",
    "train.zoom(probability=0.2, min_factor=1.1, max_factor=1.3)\n",
    "train.flip_random(0.75)\n",
    "train.resize(probability=1, width=image_shape, height=image_shape, resample_filter=u'BICUBIC')\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "traingen = ImageDataGenerator(\n",
    "      preprocessing_function = train.keras_preprocess_func(),\n",
    ")\n",
    "\n",
    "test = Augmentor.Pipeline()\n",
    "test.zoom(probability=1, min_factor=1.1, max_factor=1.2)\n",
    "test.resize(1.0, image_shape, image_shape)\n",
    "\n",
    "testgen = ImageDataGenerator(\n",
    "      preprocessing_function = test.keras_preprocess_func(),  \n",
    ")\n",
    "\n",
    "# 從中間切固定大小\n",
    "# crop_by_size(probability, width, height, centre=True) \n",
    "# 從中間擷取隨機大小 percentage_area(隨機的大小)\n",
    "# crop_centre(probability, percentage_area, randomise_percentage_area=False)\n",
    "# 隨機擷取隨機大小 \n",
    "# crop_random(probability, percentage_area, randomise_percentage_area=False)\n",
    "# 翻轉\n",
    "# traingen.flip_random(0.75)\n",
    "# 圖內變形(小區域放大縮小扭曲)\n",
    "# traingen.gaussian_distortion(0.2, 2, 2, 1, \"bell\", \"in\")\n",
    "# 增加對比度\n",
    "# histogram_equalisation(probability=1.0)\n",
    "# 亮度 0黑 1原圖\n",
    "# random_brightness(probability, min_factor, max_factor)\n",
    "# 飽和度 1 原圖\n",
    "# random_color(probability, min_factor, max_factor)\n",
    "# 對比度 1 原圖\n",
    "# random_contrast(probability, min_factor, max_factor)\n",
    "# 圖內形變\n",
    "# random_distortion(probability=0.5, grid_width=4, grid_height=8, magnitude=5)\n",
    "# 轉成指定大小\n",
    "# resize(probability, width, height, resample_filter=u'BICUBIC')\n",
    "# 隨機旋轉(最多25)\n",
    "# rotate(probability=1, max_left_rotation=24, max_right_rotation=24)\n",
    "# 旋轉 90 的倍數\n",
    "# rotate_random_90(0.75)\n",
    "# 傾斜\n",
    "# skew(probability=0.5, magnitude=0.5)\n",
    "# 放大\n",
    "# zoom(probability=0.5, min_factor=1.1, max_factor=1.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting New Model\n",
    "import tensorflow\n",
    "print(tensorflow.__version__)\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "import efficientnet.tfkeras as efn\n",
    "\n",
    "net = efn.EfficientNetB3( include_top=True, weights='imagenet'\n",
    "                         , input_tensor=None,input_shape=(image_shape,image_shape,3))\n",
    "net.summary()\n",
    "\n",
    "inpt = Input(shape=(image_shape, image_shape, 3))\n",
    "x = net(inpt)\n",
    "\n",
    "model = Model(inputs=[inpt], outputs=[x])\n",
    "model.summary()\n",
    "model.compile(  loss= ['sparse_categorical_crossentropy'],\n",
    "                optimizer= Adam(lr=0.0002 ,decay=1e-8),\n",
    "                metrics=['accuracy']\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting LookBack Function\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import os\n",
    "\n",
    "LR_function=ReduceLROnPlateau(\n",
    "    monitor='val_loss',                        \n",
    "    patience= 4, # 3 epochs 內acc沒下降就要調整LR\n",
    "    verbose=1,    \n",
    "    factor=0.5, # LR降為0.5\n",
    "#     min_lr=0.00000001\n",
    ")\n",
    "\n",
    "earlystop_function = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "#     min_delta= 0,  #容忍漲跌幅範圍\n",
    "    patience= 10,  #容忍不下降回合數\n",
    "    verbose= 1, \n",
    "    mode='min',\n",
    "#     baseline=None \n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "class save_best_model(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global best_loss\n",
    "        global best_acc\n",
    "        \n",
    "        if best_loss > logs['val_loss']:  \n",
    "            filepath='./Trained_model/{}Best_loss[{:.4f}].h5'.format(saving_name, best_loss)\n",
    "            try:\n",
    "                os.remove(filepath)\n",
    "            except:\n",
    "                None\n",
    "            best_loss = logs['val_loss']\n",
    "            filepath='./Trained_model/{}Best_loss[{:.4f}].h5'.format(saving_name, best_loss)\n",
    "            model.save(filepath)\n",
    "            print ('\\nSave',filepath)\n",
    "        else:\n",
    "            print ('\\nNot better loss than {:.4f}'.format(best_loss))\n",
    "            \n",
    "        if best_acc < logs['val_accuracy']:\n",
    "            filepath='./Trained_model/{}Best_acc[{:.4f}].h5'.format(saving_name, best_acc*100)\n",
    "            try:\n",
    "                os.remove(filepath)\n",
    "            except:\n",
    "                None\n",
    "            best_acc = logs['val_accuracy']\n",
    "            filepath='./Trained_model/{}Best_acc[{:.4f}].h5'.format(saving_name, best_acc*100)\n",
    "            model.save(filepath)\n",
    "            print ('Save',filepath)\n",
    "        else:\n",
    "            print ('Not better acc than {:.4f}'.format(best_acc))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Learning rate during Trainging\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_value(model.optimizer.lr, 0.0002500000118743628 )\n",
    "\n",
    "print (K.get_value(model.optimizer.lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training Model\n",
    "for i in range(6,10):\n",
    "    saving_name = 'Mango_EfficientNetB2[{}]'.format(i)\n",
    "################\n",
    "\n",
    "    import tensorflow as tf\n",
    "    best_loss = 100.\n",
    "    best_acc = 0.\n",
    "    tf.keras.backend.clear_session()\n",
    "    net = efn.EfficientNetB2( include_top=True, weights='imagenet'\n",
    "                         , input_tensor=None,input_shape=(image_shape,image_shape,3))\n",
    "    inpt = Input(shape=(image_shape, image_shape, 3))\n",
    "    x = net(inpt)\n",
    "    model = Model(inputs=[inpt], outputs=[x])\n",
    "    model.compile(  loss= ['sparse_categorical_crossentropy'],\n",
    "                optimizer= Adam(lr=0.0002 ,decay=1e-8),\n",
    "                metrics=['accuracy']\n",
    "                )\n",
    "\n",
    "    model.fit(traingen.flow(X_train,y_train,batch_size=35), \n",
    "                    steps_per_epoch=X_train.shape[0]/35 , epochs=300, shuffle = True,\n",
    "                    validation_data=testgen.flow(X_test,y_test,batch_size=32,shuffle=False),\n",
    "                    validation_steps=X_test.shape[0]/32,\n",
    "                    callbacks=[save_best_model(), LR_function, \n",
    "                               earlystop_function],\n",
    "                    workers = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model Score\n",
    "batch_size = 32\n",
    "\n",
    "#########################\n",
    "score = model.evaluate(testgen.flow(X_train,y_train,batch_size=batch_size,shuffle=False)\n",
    "                      ,steps = X_train.shape[0]/batch_size)\n",
    "# print (score)\n",
    "# score = model.evaluate(X_train/255.,y_train)\n",
    "# print (score)\n",
    "score = model.evaluate(testgen.flow(X_test,y_test,batch_size=batch_size,shuffle=False)\n",
    "                       ,steps = X_test.shape[0]/batch_size)\n",
    "# print (score)\n",
    "# score = model.evaluate(X_test/255.,y_test)\n",
    "# print (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Model\n",
    "model_name = 'adi_B3[5]Best_loss[0.3885].h5'\n",
    "saving_path = './Model/'+ model_name +'.h5'\n",
    "\n",
    "#################################\n",
    "model.save(saving_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Test Data\n",
    "\n",
    "test_data = np.load('./mango_test_data.npy',allow_pickle=True)\n",
    "test_name = np.load('./mango_test_name.npy',allow_pickle=True)\n",
    "test_data = resize_mango(test_data,image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Test Result\n",
    "\n",
    "ans = model.predict(testgen.flow(test_data,batch_size=batch_size,shuffle=False))\n",
    "# ans = model.predict(test_data/255.)\n",
    "\n",
    "np.save('./Predict/' + model_name + 'predict.npy',ans[:,1:4])\n",
    "\n",
    "ans = np.argmax(ans, axis=1)\n",
    "ans = list(ans)\n",
    "\n",
    "output = list()\n",
    "output.append (['image_id', 'label'])\n",
    "for idx,data in enumerate(ans):\n",
    "    if ans[idx] == 1:\n",
    "        label = 'A'\n",
    "    if ans[idx] == 2:\n",
    "        label = 'B'\n",
    "    if ans[idx] == 3:\n",
    "        label = 'C'\n",
    "    output.append([test_name[idx],label])\n",
    "\n",
    "import csv\n",
    "\n",
    "with open( './Result/' + model_name + 'ans.csv', 'w', newline='') as csvfile:\n",
    "  writer = csv.writer(csvfile)\n",
    "  writer.writerows(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "\n",
    "saving_name = ''\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('./Trained_model/Mango_EfficientNetB3[5]Best_loss[0.3885].h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
